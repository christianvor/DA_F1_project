---
title: "Untitled"
output: html_document
date: "2024-04-21"
---

# The Goal of the Analysis and Research Questions

We are working on the data set about Formula1 races since the year 2000. Our main goal is to explore the potential relations between the various variables before the races and the result of the race. We want to build a model to predict the winner of the future race based on our analysis of the previous races. Specifically, we want to answer questions such as:

- Who is gonna win the next race?

- What variables offer the best predictable value for the winner of the race?

- How strong are the relationship between the independent variables and the dependent ones?

- Are the relationships linear?

# Cleaning the data

```{r}
data <- read.csv("./data/F1_preprocessed")
head(data)

data<-na.omit(data)

data$X<-NULL #removing the redundant variable as it only shows the index
```

# Exploring correlation

```{r}
corr <- cor(data[,c(1, 2, 3, 9, 10, 11, 12, 13)]) # no categorical variables
corPlot(corr)
```
 
From the correlation plot, the most correlation is seen for variables, PositionPractice1, PositionPractice2, StartingPosition, FinishingPosition, and points, showing that those relationships would be interesting to explore further. 

# Simple linear regression

For our purposes, we choose 'FinishingPosition' as our dependend variable and others as independent variable. The smaller the Finishing Position is, the more points won, and the better result it is for the participants.

Let's take the variables we found with correlation matrix to be interesting to explore and run simple linear regression with 'FinishingPosition' as the dependent variable

```{r}
# Practice Position 1
fit_practice1<-lm(FinishingPosition~PositionPractice1, data=data)
summary(fit_practice1)
plot(FinishingPosition ~ PositionPractice1, data=data) 
abline(fit_practice1, col="red", lwd=2)

# Practice Position 2
fit_practice2<-lm(FinishingPosition~PositionPractice2, data=data)
summary(fit_practice2)
plot(FinishingPosition ~ PositionPractice2, data=data) 
abline(fit_practice2, col="red", lwd=2)

#Starting Position
fit_startposition<-lm(FinishingPosition~StartingPosition, data=data)
summary(fit_startposition)
plot(FinishingPosition ~ StartingPosition, data=data) 
abline(fit_startposition, col="red", lwd=2)
```

## Non-linearity

```{r}
# Practice Position 1
fit_practice1_log<-lm(log(FinishingPosition)~ log(PositionPractice1), data=data)
summary(fit_practice1_log) #the R-squared improves noticeably

# Practice Position 2
fit_practice2_log<-lm(log(FinishingPosition)~log(PositionPractice2), data=data)
summary(fit_practice2_log) # Again, better model fit. Shows that there are exponential trends

# Starting Position
fit_startposition_log<-lm(log(FinishingPosition)~log(StartingPosition), data=data)
summary(fit_startposition_log) # Significant improvement for goodness of fit

``` 

# Multiple Linear regression

```{r}

#fitdata<-lm(FinishingPosition~., data=data)
#summary(fitdata) #dimensions too large, can eliminate some irrelevant variables

fitAll<-lm(FinishingPosition~PositionPractice1+PositionPractice2+StartingPosition, data=data)
summary(fitAll)
```
```{r}
pairs(data[c("FinishingPosition", "PositionPractice1", "PositionPractice2", "StartingPosition")])
```
```{r}
cor(data[,9:12]) #multicollinearity?
```
## Log-log transformation for multiple linear regression

```{r}
fitAll_log<-lm(log(FinishingPosition)~log(PositionPractice1)+log(PositionPractice2)+log(StartingPosition), data=data)
summary(fitAll_log) #significant improvement for R-Squared
```
## Model comparison:

### Incorporating the other variables??

```{r}
fitdata<-lm(FinishingPosition~., data=data[,-c(1,2,4,5,8,13)]) #eliminated raceId, engineManufacturerId, year, country, officialName, and points
step_data<-step(fitdata, direction="both")
```

The best model seems to include, "round", "PositionPractice1", "PositionPractice2", "constructorId", and "Starting Position" as independent variables. 

```{r}
fitstep<-lm(FinishingPosition ~ round + constructorId + PositionPractice1 + PositionPractice2 + StartingPosition, data=data)
summary(fitstep)  #R-squared worse than fitlog
```

AIC comparison:

```{r}
aic_log<-AIC(fitAlllog)
aic_step<-AIC(fitAllstep)
print(aic_log)
print(aic_step)
```

# Predictions and Out of Sample Performance

```{r}
newdata<-data.frame(FinishingPosition=NA, round=5, constructorId="ferrari", PositionPractice1=20, PositionPractice2=4, StartingPosition=6)
predict(fitstep, newdata = newdata, interval = "confidence", level = 0.95)
```


```{r}
n <- nrow(data)
n1 <- floor(0.9*n) # number of obs in train set
set.seed(1234) ## for reproducibility
id_train <- sample(1:n, n1)
train_dat <- data[id_train, ]
test_dat  <- data[-id_train, ]
```

Fitting the models on the training set:

```{r}
fitAlllog <- lm(FinishingPosition ~ PositionPractice1 + PositionPractice2 + StartingPosition, data = train_dat)
fitAllstep<-lm(FinishingPosition ~ round + constructorId + PositionPractice1 + PositionPractice2 + StartingPosition, data=train_dat)

#predictions
yhat_log<-predict(fitAlllog, data=test_dat)
yhat_step<-predict(fitAllstep, data=test_dat)

```

Mean-squared-errors:

```{r}
sqrt(c(mean((yhat_log - test_dat$FinishingPosition)^2), 
       mean((yhat_step - test_dat$FinishingPosition)^2)))  #MSE smaller for log model. 
```


